<div align="center">

<img src="logo/logo.jpeg" alt="EdgeNPU Logo" width="200" height="200">

# EdgeNPU Design

### High-Performance Neural Processing Unit for Edge AI Applications

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![RTL](https://img.shields.io/badge/RTL-SystemVerilog-orange.svg)](#)
[![Verification](https://img.shields.io/badge/Verification-UVM-green.svg)](#)
[![Documentation](https://img.shields.io/badge/docs-available-brightgreen.svg)](https://buiminhnhut114.github.io/edge-npu-design/)
[![Build Status](https://img.shields.io/github/actions/workflow/status/buiminhnhut114/edge-npu-design/deploy-docs.yml?branch=main)](https://github.com/buiminhnhut114/edge-npu-design/actions)

**EdgeNPU** is a production-grade Neural Processing Unit (NPU) IP core designed for high-performance, low-power neural network inference at the edge. Built on a **16Ã—16 weight-stationary systolic array architecture**, EdgeNPU delivers up to **512 GOPS** peak performance while consuming less than **500mW**, achieving industry-leading efficiency of **>1 TOPS/W**.

[ğŸ“– Documentation](https://buiminhnhut114.github.io/edge-npu-design/) Â· [ğŸš€ Quick Start](#quick-start) Â· [ğŸ—ï¸ Architecture](#architecture) Â· [ğŸ¤ Contributing](#contributing)

</div>

---

## âœ¨ Key Features

| Feature | Specification |
|---------|---------------|
| **Architecture** | 16Ã—16 Weight-Stationary Systolic Array |
| **Peak Performance** | 512 GOPS (INT8) @ 1 GHz |
| **Energy Efficiency** | > 1 TOPS/W |
| **On-chip Memory** | 528 KB SRAM (Weight + Activation + Instruction) |
| **Data Types** | INT8, INT16, FP16, BF16 |
| **Interface** | AXI4 Master (128-bit) + AXI4-Lite Slave (32-bit) |
| **Process Technology** | 28nm / 16nm / 7nm ready |

### ğŸ§  Supported Neural Network Operations

- **Convolution**: Conv2D, DepthwiseConv2D, TransposeConv2D, Dilated Conv
- **Activation**: ReLU, ReLU6, Sigmoid, Tanh, Swish, GELU, LeakyReLU, HardSwish
- **Pooling**: MaxPool2D, AvgPool2D, GlobalAveragePool
- **Normalization**: BatchNorm (fused), LayerNorm
- **Element-wise**: Add, Multiply, Subtract, Concat, Split, Reshape
- **Linear**: FullyConnected, MatMul

### ğŸ”§ Technical Specifications

- **PE Array**: 16Ã—16 = 256 Processing Elements
- **Instruction Set**: 64-bit RISC-style with 12 opcodes
- **DMA Engine**: 4-channel with 2D/3D transfer support
- **Memory Bandwidth**: 16 GB/s (internal), 12.8 GB/s (external)
- **Clock Domain**: Single clock domain with optional clock gating
- **Debug Support**: JTAG interface and performance counters
- **Power Management**: Advanced clock gating and power islands

---

## ğŸ—ï¸ Architecture

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        AXI4 Interface                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ DMA Engineâ”‚  â”‚ Weight Bufferâ”‚  â”‚ Activation   â”‚  â”‚ Inst   â”‚  â”‚
â”‚  â”‚ 4-channel â”‚  â”‚   256 KB     â”‚  â”‚ Buffer 256KB â”‚  â”‚ 16 KB  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚        â”‚               â”‚                  â”‚                      â”‚
â”‚        â–¼               â–¼                  â–¼                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚            PE Array (16Ã—16 Systolic)                   â”‚    â”‚
â”‚  â”‚                  256 MACs                              â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”                      â”‚    â”‚
â”‚  â”‚  â”‚PE  â”‚ â”‚PE  â”‚ â”‚PE  â”‚ ... â”‚PE  â”‚                      â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”˜                      â”‚    â”‚
â”‚  â”‚    â”‚      â”‚      â”‚         â”‚                          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”                      â”‚    â”‚
â”‚  â”‚  â”‚PE  â”‚ â”‚PE  â”‚ â”‚PE  â”‚ ... â”‚PE  â”‚                      â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”˜                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚        â”‚                                                         â”‚
â”‚        â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Post-Processing: Activation | Pooling | Quantization   â”‚    â”‚
â”‚  â”‚ â€¢ ReLU, ReLU6, Sigmoid, Tanh, Swish, GELU             â”‚    â”‚
â”‚  â”‚ â€¢ MaxPool, AvgPool, GlobalPool                         â”‚    â”‚
â”‚  â”‚ â€¢ BatchNorm, LayerNorm                                 â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

### ğŸ”„ Weight-Stationary Dataflow

EdgeNPU employs a **weight-stationary systolic array** where weights are loaded once and remain fixed in each PE while input activations flow through the array. This approach maximizes weight reuse and minimizes memory bandwidth for weight-heavy operations like convolutions.

---

## ğŸ“ Project Structure

```
EdgeNPU/
â”œâ”€â”€ rtl/                    # RTL Design (SystemVerilog)
â”‚   â”œâ”€â”€ core/               # NPU Core
â”‚   â”‚   â”œâ”€â”€ pe_array/       # Processing Element Array
â”‚   â”‚   â”œâ”€â”€ activation/     # Activation Functions
â”‚   â”‚   â”œâ”€â”€ pooling/        # Pooling Operations
â”‚   â”‚   â”œâ”€â”€ controller/     # NPU Controller
â”‚   â”‚   â”œâ”€â”€ conv/           # Convolution Engine
â”‚   â”‚   â”œâ”€â”€ accumulator/    # Accumulator
â”‚   â”‚   â”œâ”€â”€ batchnorm/      # Batch Normalization
â”‚   â”‚   â””â”€â”€ elementwise/    # Element-wise Operations
â”‚   â”œâ”€â”€ memory/             # Memory Subsystem
â”‚   â”‚   â”œâ”€â”€ sram/           # SRAM Controllers
â”‚   â”‚   â”œâ”€â”€ buffer/         # Buffer Management
â”‚   â”‚   â””â”€â”€ dma/            # DMA Engine
â”‚   â”œâ”€â”€ interconnect/       # AXI/APB Interfaces
â”‚   â”œâ”€â”€ debug/              # Debug Interface
â”‚   â””â”€â”€ top/                # Top-level Integration
â”œâ”€â”€ verification/           # Verification Environment
â”‚   â”œâ”€â”€ testbench/          # Testbenches
â”‚   â”œâ”€â”€ uvm/                # UVM Environment
â”‚   â””â”€â”€ formal/             # Formal Verification
â”œâ”€â”€ software/               # Software Stack
â”‚   â”œâ”€â”€ driver/             # Linux & Bare-metal Drivers
â”‚   â”œâ”€â”€ compiler/           # Model Compiler (ONNX, TFLite)
â”‚   â”œâ”€â”€ runtime/            # Runtime Library
â”‚   â”œâ”€â”€ firmware/           # Firmware
â”‚   â””â”€â”€ sdk/                # C/C++/Python SDK
â”œâ”€â”€ ip/                     # IP Cores
â”‚   â”œâ”€â”€ memory/             # Memory IP
â”‚   â”œâ”€â”€ axi/                # AXI IP
â”‚   â”œâ”€â”€ npu/                # NPU-specific IP
â”‚   â””â”€â”€ third_party/        # Third-party IP
â”œâ”€â”€ flow/                   # Build & Synthesis Flow
â”‚   â”œâ”€â”€ build/              # Build Scripts
â”‚   â”œâ”€â”€ scripts/            # Automation Scripts
â”‚   â””â”€â”€ synthesis/          # Synthesis Scripts (OpenLane)
â”œâ”€â”€ doc-sites/              # Interactive Documentation Website
â””â”€â”€ logo/                   # EdgeNPU Logo Assets
```

---

## ğŸš€ Quick Start

### ğŸ“‹ System Requirements

- **OS**: Ubuntu 20.04+ / CentOS 7+ / macOS 10.15+
- **Simulator**: Icarus Verilog, Verilator, or commercial (VCS, Questa)
- **Python**: 3.8+ (for SDK and compiler)
- **Node.js**: 18+ (for documentation site)

### ğŸ› ï¸ Installation

```bash
# Clone repository
git clone https://github.com/buiminhnhut114/edge-npu-design.git
cd edge-npu-design

# Install Python dependencies
pip install -r requirements.txt

# Install simulation tools (Ubuntu/Debian)
sudo apt update
sudo apt install iverilog verilator gtkwave

# Install simulation tools (macOS)
brew install icarus-verilog verilator gtkwave
```

### ğŸ§ª Running Simulations

```bash
# Run all unit tests
make test

# Run PE unit test
make sim_pe

# Run PE array simulation
make sim_pe_array

# Run full system simulation
make sim

# Run UVM testbench
make uvm

# Lint RTL code
make lint

# View waveforms
gtkwave npu_tb.vcd

# Clean build artifacts
make clean
```

### ğŸ’» RTL Integration Example

```systemverilog
// Instantiate EdgeNPU in your SoC
npu_top #(
    .PE_ROWS     (16),
    .PE_COLS     (16),
    .DATA_WIDTH  (8),
    .AXI_DATA_W  (128),
    .AXI_ADDR_W  (40)
) u_edgenpu (
    .clk         (npu_clk),
    .rst_n       (npu_rst_n),
    // AXI4 Master interface
    .m_axi_*     (axi_master_*),
    // AXI4-Lite Slave interface  
    .s_axil_*    (axil_slave_*),
    // Interrupt
    .irq         (npu_irq)
);
```

### ğŸŒ Building Documentation

```bash
cd doc-sites
npm install
npm run dev      # Development server at http://localhost:3000
npm run build    # Production build
```

---

## ğŸ“Š Performance Benchmarks

| Model | Input Size | Latency | Throughput | Power |
|-------|------------|---------|------------|-------|
| MobileNetV1 | 224Ã—224 | 2.1 ms | 476 FPS | 320 mW |
| MobileNetV2 | 224Ã—224 | 2.8 ms | 357 FPS | 340 mW |
| MobileNetV3-Small | 224Ã—224 | 1.5 ms | 667 FPS | 280 mW |
| EfficientNet-Lite0 | 224Ã—224 | 3.2 ms | 312 FPS | 360 mW |
| ResNet-18 | 224Ã—224 | 8.5 ms | 118 FPS | 420 mW |
| YOLO-Tiny | 416Ã—416 | 12.3 ms | 81 FPS | 450 mW |
| SSD-MobileNetV2 | 300Ã—300 | 6.8 ms | 147 FPS | 380 mW |

*Benchmarks measured at 800 MHz clock frequency with INT8 quantization*

### ğŸ† Efficiency Comparison

| Platform | Peak TOPS | Power | TOPS/W | Process |
|----------|-----------|-------|--------|---------|
| **EdgeNPU** | **0.51** | **0.5W** | **1.02** | **28nm** |
| Google Edge TPU | 4.0 | 2.0W | 2.0 | â€” |
| Intel Movidius | 1.0 | 1.5W | 0.67 | â€” |
| ARM Ethos-U55 | 0.5 | 0.5W | 1.0 | â€” |
| Cortex-A76 (CPU) | 0.02 | 2.0W | 0.01 | 7nm |

---

## ğŸ“š Documentation

ğŸ“– **[Complete Documentation](https://buiminhnhut114.github.io/edge-npu-design/)**

- [ğŸ—ï¸ System Architecture](https://buiminhnhut114.github.io/edge-npu-design/#/system-architecture)
- [ğŸ”§ Register Map](https://buiminhnhut114.github.io/edge-npu-design/#/register-map)
- [ğŸ“ Programming Guide](https://buiminhnhut114.github.io/edge-npu-design/#/programming-overview)
- [ğŸ”— Integration Guide](https://buiminhnhut114.github.io/edge-npu-design/#/soc-integration)
- [ğŸ“‹ API Reference](https://buiminhnhut114.github.io/edge-npu-design/#/c-api)
- [ğŸ Python SDK](https://buiminhnhut114.github.io/edge-npu-design/#/python-api)

---

## ğŸ› ï¸ Technology Stack

| Category | Technology |
|----------|------------|
| **RTL Design** | SystemVerilog, Verilog-2005 |
| **Verification** | UVM, SystemVerilog Assertions, Formal |
| **Synthesis** | OpenLane, Synopsys DC, Cadence Genus |
| **Simulation** | VCS, Questa, Verilator, Icarus Verilog |
| **Software** | C/C++, Python, ONNX, TensorFlow Lite |
| **Documentation** | React, TypeScript, Vite, SVG |
| **CI/CD** | GitHub Actions, Docker |

---

## ğŸ—ºï¸ Development Roadmap

### âœ… Completed Features

- [x] PE Array implementation (Systolic)
- [x] Basic activation functions (ReLU, ReLU6, Sigmoid, Tanh, Swish, GELU)
- [x] AXI4/AXI4-Lite interfaces
- [x] 4-channel DMA engine
- [x] Memory subsystem (Weight, Activation, Instruction buffers)
- [x] Post-processing units (Activation, Pooling, BatchNorm)
- [x] Convolution controller and Depthwise convolution
- [x] Element-wise operations (Add, Multiply, Concat, Split)
- [x] Instruction decoder and scheduler
- [x] Debug interface
- [x] Comprehensive documentation site
- [x] UVM verification environment

### ğŸš§ In Progress

- [ ] Depthwise convolution optimization
- [ ] Full FP16/BF16 support
- [ ] Power gating implementation
- [ ] OpenLane synthesis flow
- [ ] Python SDK enhancements

### ğŸ”® Future Plans

- [ ] On-device training support
- [ ] Dynamic quantization
- [ ] Multi-core scaling
- [ ] RISC-V integration
- [ ] Transformer acceleration
- [ ] Edge TPU compatibility layer

---

## ğŸ¤ Contributing

We welcome contributions! Please read our [Contributing Guidelines](CONTRIBUTING.md) before submitting PRs.

### ğŸ”„ Development Workflow

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### ğŸ› Bug Reports

Please use GitHub Issues to report bugs. Include:
- System information (OS, simulator, versions)
- Steps to reproduce
- Expected vs actual behavior
- Relevant logs or waveforms

### ğŸ’¡ Feature Requests

We're always looking for ways to improve EdgeNPU! Feel free to suggest new features or enhancements through GitHub Issues.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ“– Citation

If you use EdgeNPU in your research, please cite:

```bibtex
@misc{edgenpu2026,
  title={EdgeNPU: High-Performance Neural Processing Unit for Edge AI},
  author={Bui Minh Nhut},
  year={2026},
  howpublished={\url{https://github.com/buiminhnhut114/edge-npu-design}},
  note={Open-source NPU design for edge AI applications}
}
```

---

## ğŸ™ Acknowledgments

- Inspired by Google's TPU and ARM's Ethos-U architectures
- Built with modern SystemVerilog and UVM methodologies
- Documentation powered by React and modern web technologies
- Community feedback and contributions

---

## ğŸ“ Contact & Support

- **GitHub Issues**: [Report bugs or request features](https://github.com/buiminhnhut114/edge-npu-design/issues)
- **Documentation**: [https://buiminhnhut114.github.io/edge-npu-design/](https://buiminhnhut114.github.io/edge-npu-design/)
- **Email**: [Contact the maintainer](mailto:buiminhnhut114@gmail.com)

---

<div align="center">

**EdgeNPU** â€” Designed for Edge, Built for Performance

Made with â¤ï¸ for the open-source hardware community

[â¬† Back to top](#edgenpu-design)

</div>